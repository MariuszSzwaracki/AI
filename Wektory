import os
import json
import pickle
import sys
import numpy as np
from tqdm import tqdm
import torch
from sentence_transformers import SentenceTransformer

# --- KONFIGURACJA ---
FOLDER_PATH = r'./test'    # Folder z plikami JSON
MODEL_NAME = 'BAAI/bge-m3' 
OUTPUT_DB = 'baza_wiedzy.pkl'
OUTPUT_VEC = 'wektory_tytulow.npy'

def load_json_files(folder):
    data_list = []
    if not os.path.exists(folder):
        print(f"âŒ BÅ‚Ä…d: Nie znaleziono folderu '{folder}'!")
        return []

    # Pobieranie listy plikÃ³w JSON (rÃ³wnieÅ¼ z podfolderÃ³w, jeÅ›li sÄ…)
    files = []
    for root, dirs, filenames in os.walk(folder):
        for filename in filenames:
            if filename.lower().endswith('.json'):
                files.append(os.path.join(root, filename))

    print(f"ğŸ“‚ Znaleziono {len(files)} plikÃ³w JSON. Przetwarzanie...")

    for filepath in tqdm(files, unit="plik"):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = json.load(f)
                
                # ObsÅ‚uga sytuacji, gdy w pliku jest jeden obiekt lub lista obiektÃ³w
                if isinstance(content, list):
                    items = content
                else:
                    items = [content]

                for item in items:
                    # Sprawdzenie czy to wÅ‚aÅ›ciwe dane (czy majÄ… klucz 'id' lub 'tytul')
                    if 'tytul' not in item and 'opis' not in item:
                        continue
                        
                    # --- TWORZENIE TEKSTU DLA AI (SEMANTYCZNEGO) ---
                    # ÅÄ…czymy kluczowe pola, Å¼eby AI wiedziaÅ‚o co to jest.
                    # Np.: "Pani szuka pana. PoszukujÄ™ mÄ™Å¼czyzny. Opis:..."
                    
                    full_text_for_ai = (
                        f"Kategoria: {item.get('kategoria', '')}. "
                        f"Miasto: {item.get('lokalizacja', '')}. "
                        f"Wiek: {item.get('wiek', '')}. "
                        f"{item.get('tytul', '')}. "
                        f"{item.get('opis', '')}"
                    )
                    
                    # Dodajemy pole 'title' i 'headers' dla kompatybilnoÅ›ci z generatorem
                    # 'title' to bÄ™dzie tytuÅ‚ ogÅ‚oszenia
                    # 'headers' to bÄ™dÄ… zdania z opisu (Å¼eby generator miaÅ‚ co "cytowaÄ‡")
                    
                    raw_desc = item.get('opis', '')
                    if raw_desc:
                        # Prosty podziaÅ‚ opisu na zdania jako "rozdziaÅ‚y/nagÅ‚Ã³wki"
                        pseudo_headers = [s.strip() for s in raw_desc.replace('!', '.').replace('?', '.').split('.') if len(s) > 10]
                    else:
                        pseudo_headers = ["Brak opisu"]

                    # Budujemy obiekt do bazy
                    entry = {
                        'original_id': item.get('id'),
                        'title': item.get('tytul', 'Bez tytuÅ‚u'), # Dla generatora
                        'headers': pseudo_headers,                # Dla generatora
                        'full_text': full_text_for_ai,            # To bÄ™dziemy wektoryzowaÄ‡
                        'metadata': item                          # Zachowujemy oryginaÅ‚ w caÅ‚oÅ›ci
                    }
                    data_list.append(entry)

        except Exception as e:
            print(f"âš ï¸ BÅ‚Ä…d w pliku {filepath}: {e}")
            continue

    return data_list

def main():
    # 1. Wczytywanie danych z plikÃ³w
    docs = load_json_files(FOLDER_PATH)
    if not docs:
        print("âŒ Brak danych do przetworzenia.")
        return
    
    print(f"âœ… ZaÅ‚adowano {len(docs)} ogÅ‚oszeÅ„.")

    # 2. Åadowanie modelu
    print(f"â³ Åadowanie modelu {MODEL_NAME}...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    try:
        model = SentenceTransformer(MODEL_NAME, device=device)
    except ImportError:
        sys.exit("âŒ Brak bibliotek. Zainstaluj: pip install sentence-transformers torch numpy tqdm")

    # 3. Generowanie embeddingÃ³w
    print("ğŸ§  Generowanie wektorÃ³w (to moÅ¼e chwilÄ™ potrwaÄ‡)...")
    
    # Wektoryzujemy przygotowany 'full_text' (czyli poÅ‚Ä…czenie kategorii, tytuÅ‚u i opisu)
    texts_to_encode = [d['full_text'] for d in docs]
    
    # Batch size dobrany bezpiecznie
    embeddings = model.encode(texts_to_encode, show_progress_bar=True, batch_size=32, convert_to_numpy=True)

    # 4. Zapisywanie wynikÃ³w
    print(f"\nğŸ’¾ ZAPISYWANIE BAZY DANYCH...")
    
    # Zapis wektorÃ³w (.npy)
    np.save(OUTPUT_VEC, embeddings)
    print(f"   -> Zapisano wektory: {OUTPUT_VEC}")
    
    # Zapis struktury (.pkl)
    # Usuwamy 'full_text' przed zapisem, Å¼eby plik byÅ‚ lÅ¼ejszy (chyba Å¼e chcesz go mieÄ‡)
    # Tutaj zostawiam, bo moÅ¼e siÄ™ przydaÄ‡.
    with open(OUTPUT_DB, 'wb') as f:
        pickle.dump(docs, f)
    print(f"   -> Zapisano bazÄ™: {OUTPUT_DB}")

    print("\nâœ… GOTOWE! MoÅ¼esz teraz uÅ¼yÄ‡ generatora.")

if __name__ == "__main__":
    main()
